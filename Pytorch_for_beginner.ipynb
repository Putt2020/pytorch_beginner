{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Putt2020/pytorch_beginner/blob/main/Pytorch_for_beginner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor"
      ],
      "metadata": {
        "id": "c6IGJveM96Ef"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "id": "zYwv5oaZ99iO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f431405a-5aa7-4f3f-fdaa-c15dd71ae377"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 9928113.64it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 201589.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:06<00:00, 675389.54it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 22283051.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Define dataloader for train and test \"\"\"\n",
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "id": "_KWFrqmB9_mH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e63bccf3-2ca4-44d7-8d14-7b194ac3843d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" define Model \"\"\"\n",
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# Define model\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "SpPQmWlR9_kI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39829eda-427d-4a81-b06a-47584aac9152"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Loss function for model \"\"\"\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "OI9ynfVp9_dO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "fMCbR-aIgBmM"
      },
      "outputs": [],
      "source": [
        "\"\"\" Define train test function \"\"\"\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Train Model \"\"\"\n",
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtpFgS-U-9-V",
        "outputId": "3feeaa06-a703-4912-f6f5-bcba75683000"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.308218  [   64/60000]\n",
            "loss: 2.295139  [ 6464/60000]\n",
            "loss: 2.271226  [12864/60000]\n",
            "loss: 2.264940  [19264/60000]\n",
            "loss: 2.252426  [25664/60000]\n",
            "loss: 2.215834  [32064/60000]\n",
            "loss: 2.240029  [38464/60000]\n",
            "loss: 2.201779  [44864/60000]\n",
            "loss: 2.188384  [51264/60000]\n",
            "loss: 2.160230  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 33.8%, Avg loss: 2.153940 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.163889  [   64/60000]\n",
            "loss: 2.156354  [ 6464/60000]\n",
            "loss: 2.094474  [12864/60000]\n",
            "loss: 2.116470  [19264/60000]\n",
            "loss: 2.064284  [25664/60000]\n",
            "loss: 1.998441  [32064/60000]\n",
            "loss: 2.044420  [38464/60000]\n",
            "loss: 1.960733  [44864/60000]\n",
            "loss: 1.963473  [51264/60000]\n",
            "loss: 1.892882  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 55.3%, Avg loss: 1.886419 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.919971  [   64/60000]\n",
            "loss: 1.892129  [ 6464/60000]\n",
            "loss: 1.768477  [12864/60000]\n",
            "loss: 1.817862  [19264/60000]\n",
            "loss: 1.698958  [25664/60000]\n",
            "loss: 1.652034  [32064/60000]\n",
            "loss: 1.688119  [38464/60000]\n",
            "loss: 1.581218  [44864/60000]\n",
            "loss: 1.606994  [51264/60000]\n",
            "loss: 1.498500  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 61.7%, Avg loss: 1.508426 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.580361  [   64/60000]\n",
            "loss: 1.545785  [ 6464/60000]\n",
            "loss: 1.383573  [12864/60000]\n",
            "loss: 1.462028  [19264/60000]\n",
            "loss: 1.333788  [25664/60000]\n",
            "loss: 1.336648  [32064/60000]\n",
            "loss: 1.356429  [38464/60000]\n",
            "loss: 1.275210  [44864/60000]\n",
            "loss: 1.310193  [51264/60000]\n",
            "loss: 1.209647  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.0%, Avg loss: 1.232643 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.312480  [   64/60000]\n",
            "loss: 1.300534  [ 6464/60000]\n",
            "loss: 1.120357  [12864/60000]\n",
            "loss: 1.233176  [19264/60000]\n",
            "loss: 1.102702  [25664/60000]\n",
            "loss: 1.135295  [32064/60000]\n",
            "loss: 1.159072  [38464/60000]\n",
            "loss: 1.090406  [44864/60000]\n",
            "loss: 1.130302  [51264/60000]\n",
            "loss: 1.049296  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 65.2%, Avg loss: 1.068584 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Save Model \"\"\"\n",
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lihV16Az--Tl",
        "outputId": "80e1b546-acae-495c-aa7e-16df4a78f0b1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5xo61SX--bb",
        "outputId": "61326936-cd97-4c77-ef58-93c9de6ab691"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0tBF7Lp8--gX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wwt-fZzq--jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G4TOM-NC--mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jnpmba2e--pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6pkDNC_6--r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S4dw4yJz--uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibaekdVnU5aQ",
        "outputId": "34e0849e-0dab-4c0e-fd4f-086767680c70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Epoch 1/500\n",
            "422/422 [==============================] - 12s 10ms/step - loss: 2.3334 - accuracy: 0.0934 - val_loss: 2.3171 - val_accuracy: 0.0910\n",
            "Epoch 2/500\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 2.3005 - accuracy: 0.1026 - val_loss: 2.2844 - val_accuracy: 0.1020\n",
            "Epoch 3/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 2.2700 - accuracy: 0.1182 - val_loss: 2.2532 - val_accuracy: 0.1250\n",
            "Epoch 4/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 2.2406 - accuracy: 0.1426 - val_loss: 2.2227 - val_accuracy: 0.1543\n",
            "Epoch 5/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 2.2114 - accuracy: 0.1823 - val_loss: 2.1921 - val_accuracy: 0.2070\n",
            "Epoch 6/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 2.1818 - accuracy: 0.2331 - val_loss: 2.1607 - val_accuracy: 0.2720\n",
            "Epoch 7/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 2.1511 - accuracy: 0.2971 - val_loss: 2.1281 - val_accuracy: 0.3442\n",
            "Epoch 8/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 2.1191 - accuracy: 0.3650 - val_loss: 2.0938 - val_accuracy: 0.4035\n",
            "Epoch 9/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 2.0854 - accuracy: 0.4240 - val_loss: 2.0578 - val_accuracy: 0.4558\n",
            "Epoch 10/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 2.0498 - accuracy: 0.4705 - val_loss: 2.0195 - val_accuracy: 0.5015\n",
            "Epoch 11/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 2.0121 - accuracy: 0.5106 - val_loss: 1.9792 - val_accuracy: 0.5410\n",
            "Epoch 12/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.9724 - accuracy: 0.5445 - val_loss: 1.9367 - val_accuracy: 0.5758\n",
            "Epoch 13/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.9305 - accuracy: 0.5726 - val_loss: 1.8919 - val_accuracy: 0.6060\n",
            "Epoch 14/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 1.8866 - accuracy: 0.5960 - val_loss: 1.8452 - val_accuracy: 0.6297\n",
            "Epoch 15/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 1.8410 - accuracy: 0.6160 - val_loss: 1.7970 - val_accuracy: 0.6477\n",
            "Epoch 16/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.7940 - accuracy: 0.6316 - val_loss: 1.7472 - val_accuracy: 0.6602\n",
            "Epoch 17/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.7458 - accuracy: 0.6454 - val_loss: 1.6963 - val_accuracy: 0.6707\n",
            "Epoch 18/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.6967 - accuracy: 0.6558 - val_loss: 1.6450 - val_accuracy: 0.6833\n",
            "Epoch 19/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.6475 - accuracy: 0.6652 - val_loss: 1.5936 - val_accuracy: 0.6918\n",
            "Epoch 20/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.5984 - accuracy: 0.6733 - val_loss: 1.5427 - val_accuracy: 0.7010\n",
            "Epoch 21/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 1.5500 - accuracy: 0.6811 - val_loss: 1.4926 - val_accuracy: 0.7098\n",
            "Epoch 22/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 1.5024 - accuracy: 0.6882 - val_loss: 1.4434 - val_accuracy: 0.7192\n",
            "Epoch 23/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.4560 - accuracy: 0.6950 - val_loss: 1.3956 - val_accuracy: 0.7247\n",
            "Epoch 24/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.4110 - accuracy: 0.7008 - val_loss: 1.3495 - val_accuracy: 0.7308\n",
            "Epoch 25/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.3679 - accuracy: 0.7078 - val_loss: 1.3055 - val_accuracy: 0.7378\n",
            "Epoch 26/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.3266 - accuracy: 0.7136 - val_loss: 1.2633 - val_accuracy: 0.7442\n",
            "Epoch 27/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 1.2873 - accuracy: 0.7197 - val_loss: 1.2233 - val_accuracy: 0.7512\n",
            "Epoch 28/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 1.2500 - accuracy: 0.7252 - val_loss: 1.1854 - val_accuracy: 0.7573\n",
            "Epoch 29/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.2147 - accuracy: 0.7307 - val_loss: 1.1495 - val_accuracy: 0.7630\n",
            "Epoch 30/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.1813 - accuracy: 0.7359 - val_loss: 1.1155 - val_accuracy: 0.7688\n",
            "Epoch 31/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.1495 - accuracy: 0.7412 - val_loss: 1.0833 - val_accuracy: 0.7730\n",
            "Epoch 32/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.1195 - accuracy: 0.7466 - val_loss: 1.0528 - val_accuracy: 0.7790\n",
            "Epoch 33/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.0911 - accuracy: 0.7513 - val_loss: 1.0239 - val_accuracy: 0.7850\n",
            "Epoch 34/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 1.0641 - accuracy: 0.7560 - val_loss: 0.9965 - val_accuracy: 0.7887\n",
            "Epoch 35/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.0385 - accuracy: 0.7615 - val_loss: 0.9706 - val_accuracy: 0.7935\n",
            "Epoch 36/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 1.0143 - accuracy: 0.7659 - val_loss: 0.9461 - val_accuracy: 0.7985\n",
            "Epoch 37/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.9913 - accuracy: 0.7699 - val_loss: 0.9227 - val_accuracy: 0.8035\n",
            "Epoch 38/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.9694 - accuracy: 0.7744 - val_loss: 0.9005 - val_accuracy: 0.8075\n",
            "Epoch 39/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.9486 - accuracy: 0.7783 - val_loss: 0.8795 - val_accuracy: 0.8128\n",
            "Epoch 40/500\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.9289 - accuracy: 0.7824 - val_loss: 0.8596 - val_accuracy: 0.8165\n",
            "Epoch 41/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.9102 - accuracy: 0.7863 - val_loss: 0.8406 - val_accuracy: 0.8202\n",
            "Epoch 42/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.8923 - accuracy: 0.7896 - val_loss: 0.8225 - val_accuracy: 0.8243\n",
            "Epoch 43/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.8753 - accuracy: 0.7928 - val_loss: 0.8053 - val_accuracy: 0.8268\n",
            "Epoch 44/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.8591 - accuracy: 0.7960 - val_loss: 0.7890 - val_accuracy: 0.8283\n",
            "Epoch 45/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.8436 - accuracy: 0.7992 - val_loss: 0.7733 - val_accuracy: 0.8317\n",
            "Epoch 46/500\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.8288 - accuracy: 0.8019 - val_loss: 0.7583 - val_accuracy: 0.8340\n",
            "Epoch 47/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.8146 - accuracy: 0.8052 - val_loss: 0.7440 - val_accuracy: 0.8370\n",
            "Epoch 48/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.8009 - accuracy: 0.8080 - val_loss: 0.7302 - val_accuracy: 0.8392\n",
            "Epoch 49/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.7879 - accuracy: 0.8105 - val_loss: 0.7171 - val_accuracy: 0.8415\n",
            "Epoch 50/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.7754 - accuracy: 0.8130 - val_loss: 0.7044 - val_accuracy: 0.8432\n",
            "Epoch 51/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.7633 - accuracy: 0.8159 - val_loss: 0.6923 - val_accuracy: 0.8445\n",
            "Epoch 52/500\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.7517 - accuracy: 0.8181 - val_loss: 0.6807 - val_accuracy: 0.8470\n",
            "Epoch 53/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.7405 - accuracy: 0.8204 - val_loss: 0.6694 - val_accuracy: 0.8485\n",
            "Epoch 54/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.7298 - accuracy: 0.8225 - val_loss: 0.6587 - val_accuracy: 0.8502\n",
            "Epoch 55/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.7194 - accuracy: 0.8249 - val_loss: 0.6483 - val_accuracy: 0.8522\n",
            "Epoch 56/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.7094 - accuracy: 0.8270 - val_loss: 0.6382 - val_accuracy: 0.8547\n",
            "Epoch 57/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.6997 - accuracy: 0.8289 - val_loss: 0.6286 - val_accuracy: 0.8572\n",
            "Epoch 58/500\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.6904 - accuracy: 0.8308 - val_loss: 0.6194 - val_accuracy: 0.8582\n",
            "Epoch 59/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.6815 - accuracy: 0.8323 - val_loss: 0.6104 - val_accuracy: 0.8600\n",
            "Epoch 60/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.6728 - accuracy: 0.8340 - val_loss: 0.6017 - val_accuracy: 0.8618\n",
            "Epoch 61/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.6643 - accuracy: 0.8358 - val_loss: 0.5933 - val_accuracy: 0.8640\n",
            "Epoch 62/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.6562 - accuracy: 0.8376 - val_loss: 0.5852 - val_accuracy: 0.8657\n",
            "Epoch 63/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.6483 - accuracy: 0.8395 - val_loss: 0.5774 - val_accuracy: 0.8668\n",
            "Epoch 64/500\n",
            "422/422 [==============================] - 3s 6ms/step - loss: 0.6406 - accuracy: 0.8408 - val_loss: 0.5698 - val_accuracy: 0.8682\n",
            "Epoch 65/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.6331 - accuracy: 0.8424 - val_loss: 0.5624 - val_accuracy: 0.8690\n",
            "Epoch 66/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.6259 - accuracy: 0.8440 - val_loss: 0.5553 - val_accuracy: 0.8703\n",
            "Epoch 67/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.6189 - accuracy: 0.8455 - val_loss: 0.5484 - val_accuracy: 0.8717\n",
            "Epoch 68/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.6120 - accuracy: 0.8472 - val_loss: 0.5417 - val_accuracy: 0.8733\n",
            "Epoch 69/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.6054 - accuracy: 0.8486 - val_loss: 0.5351 - val_accuracy: 0.8747\n",
            "Epoch 70/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.5990 - accuracy: 0.8500 - val_loss: 0.5288 - val_accuracy: 0.8755\n",
            "Epoch 71/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.5927 - accuracy: 0.8513 - val_loss: 0.5226 - val_accuracy: 0.8770\n",
            "Epoch 72/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.5866 - accuracy: 0.8527 - val_loss: 0.5166 - val_accuracy: 0.8783\n",
            "Epoch 73/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.5806 - accuracy: 0.8540 - val_loss: 0.5108 - val_accuracy: 0.8790\n",
            "Epoch 74/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.5747 - accuracy: 0.8551 - val_loss: 0.5051 - val_accuracy: 0.8802\n",
            "Epoch 75/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.5691 - accuracy: 0.8559 - val_loss: 0.4996 - val_accuracy: 0.8812\n",
            "Epoch 76/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.5636 - accuracy: 0.8570 - val_loss: 0.4942 - val_accuracy: 0.8818\n",
            "Epoch 77/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.5582 - accuracy: 0.8578 - val_loss: 0.4890 - val_accuracy: 0.8828\n",
            "Epoch 78/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.5529 - accuracy: 0.8589 - val_loss: 0.4839 - val_accuracy: 0.8832\n",
            "Epoch 79/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.5478 - accuracy: 0.8598 - val_loss: 0.4790 - val_accuracy: 0.8840\n",
            "Epoch 80/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.5428 - accuracy: 0.8608 - val_loss: 0.4742 - val_accuracy: 0.8858\n",
            "Epoch 81/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.5380 - accuracy: 0.8619 - val_loss: 0.4695 - val_accuracy: 0.8860\n",
            "Epoch 82/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.5332 - accuracy: 0.8630 - val_loss: 0.4649 - val_accuracy: 0.8867\n",
            "Epoch 83/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.5285 - accuracy: 0.8638 - val_loss: 0.4604 - val_accuracy: 0.8877\n",
            "Epoch 84/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.5240 - accuracy: 0.8649 - val_loss: 0.4560 - val_accuracy: 0.8882\n",
            "Epoch 85/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.5195 - accuracy: 0.8657 - val_loss: 0.4518 - val_accuracy: 0.8885\n",
            "Epoch 86/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.5152 - accuracy: 0.8666 - val_loss: 0.4476 - val_accuracy: 0.8893\n",
            "Epoch 87/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.5109 - accuracy: 0.8674 - val_loss: 0.4435 - val_accuracy: 0.8898\n",
            "Epoch 88/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.5067 - accuracy: 0.8680 - val_loss: 0.4395 - val_accuracy: 0.8903\n",
            "Epoch 89/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.5026 - accuracy: 0.8690 - val_loss: 0.4357 - val_accuracy: 0.8902\n",
            "Epoch 90/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.4987 - accuracy: 0.8699 - val_loss: 0.4319 - val_accuracy: 0.8912\n",
            "Epoch 91/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4948 - accuracy: 0.8705 - val_loss: 0.4282 - val_accuracy: 0.8923\n",
            "Epoch 92/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4910 - accuracy: 0.8714 - val_loss: 0.4246 - val_accuracy: 0.8932\n",
            "Epoch 93/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4872 - accuracy: 0.8720 - val_loss: 0.4211 - val_accuracy: 0.8940\n",
            "Epoch 94/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4836 - accuracy: 0.8729 - val_loss: 0.4176 - val_accuracy: 0.8942\n",
            "Epoch 95/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.4799 - accuracy: 0.8737 - val_loss: 0.4142 - val_accuracy: 0.8950\n",
            "Epoch 96/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.4764 - accuracy: 0.8747 - val_loss: 0.4109 - val_accuracy: 0.8958\n",
            "Epoch 97/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4730 - accuracy: 0.8751 - val_loss: 0.4076 - val_accuracy: 0.8965\n",
            "Epoch 98/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4696 - accuracy: 0.8759 - val_loss: 0.4045 - val_accuracy: 0.8968\n",
            "Epoch 99/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4663 - accuracy: 0.8764 - val_loss: 0.4014 - val_accuracy: 0.8983\n",
            "Epoch 100/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4631 - accuracy: 0.8775 - val_loss: 0.3983 - val_accuracy: 0.8993\n",
            "Epoch 101/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4599 - accuracy: 0.8782 - val_loss: 0.3954 - val_accuracy: 0.8997\n",
            "Epoch 102/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.4568 - accuracy: 0.8789 - val_loss: 0.3925 - val_accuracy: 0.9002\n",
            "Epoch 103/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4538 - accuracy: 0.8795 - val_loss: 0.3897 - val_accuracy: 0.9010\n",
            "Epoch 104/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4508 - accuracy: 0.8800 - val_loss: 0.3869 - val_accuracy: 0.9023\n",
            "Epoch 105/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4478 - accuracy: 0.8807 - val_loss: 0.3841 - val_accuracy: 0.9032\n",
            "Epoch 106/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4449 - accuracy: 0.8814 - val_loss: 0.3814 - val_accuracy: 0.9035\n",
            "Epoch 107/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4421 - accuracy: 0.8821 - val_loss: 0.3788 - val_accuracy: 0.9043\n",
            "Epoch 108/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.4393 - accuracy: 0.8827 - val_loss: 0.3762 - val_accuracy: 0.9047\n",
            "Epoch 109/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4366 - accuracy: 0.8834 - val_loss: 0.3737 - val_accuracy: 0.9055\n",
            "Epoch 110/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4339 - accuracy: 0.8841 - val_loss: 0.3712 - val_accuracy: 0.9058\n",
            "Epoch 111/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4312 - accuracy: 0.8849 - val_loss: 0.3687 - val_accuracy: 0.9063\n",
            "Epoch 112/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4286 - accuracy: 0.8855 - val_loss: 0.3663 - val_accuracy: 0.9068\n",
            "Epoch 113/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4261 - accuracy: 0.8862 - val_loss: 0.3640 - val_accuracy: 0.9072\n",
            "Epoch 114/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.4236 - accuracy: 0.8868 - val_loss: 0.3617 - val_accuracy: 0.9077\n",
            "Epoch 115/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.4211 - accuracy: 0.8874 - val_loss: 0.3594 - val_accuracy: 0.9078\n",
            "Epoch 116/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4187 - accuracy: 0.8878 - val_loss: 0.3572 - val_accuracy: 0.9078\n",
            "Epoch 117/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4163 - accuracy: 0.8885 - val_loss: 0.3550 - val_accuracy: 0.9083\n",
            "Epoch 118/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4140 - accuracy: 0.8891 - val_loss: 0.3528 - val_accuracy: 0.9087\n",
            "Epoch 119/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4117 - accuracy: 0.8898 - val_loss: 0.3507 - val_accuracy: 0.9087\n",
            "Epoch 120/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4094 - accuracy: 0.8906 - val_loss: 0.3486 - val_accuracy: 0.9092\n",
            "Epoch 121/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.4072 - accuracy: 0.8911 - val_loss: 0.3466 - val_accuracy: 0.9097\n",
            "Epoch 122/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4050 - accuracy: 0.8917 - val_loss: 0.3446 - val_accuracy: 0.9102\n",
            "Epoch 123/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4028 - accuracy: 0.8923 - val_loss: 0.3426 - val_accuracy: 0.9105\n",
            "Epoch 124/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.4007 - accuracy: 0.8926 - val_loss: 0.3407 - val_accuracy: 0.9115\n",
            "Epoch 125/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3986 - accuracy: 0.8931 - val_loss: 0.3388 - val_accuracy: 0.9120\n",
            "Epoch 126/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3966 - accuracy: 0.8936 - val_loss: 0.3369 - val_accuracy: 0.9122\n",
            "Epoch 127/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.3945 - accuracy: 0.8940 - val_loss: 0.3351 - val_accuracy: 0.9127\n",
            "Epoch 128/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.3925 - accuracy: 0.8944 - val_loss: 0.3332 - val_accuracy: 0.9130\n",
            "Epoch 129/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3906 - accuracy: 0.8947 - val_loss: 0.3314 - val_accuracy: 0.9135\n",
            "Epoch 130/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3886 - accuracy: 0.8950 - val_loss: 0.3297 - val_accuracy: 0.9138\n",
            "Epoch 131/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3867 - accuracy: 0.8957 - val_loss: 0.3280 - val_accuracy: 0.9142\n",
            "Epoch 132/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3849 - accuracy: 0.8962 - val_loss: 0.3263 - val_accuracy: 0.9143\n",
            "Epoch 133/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.3830 - accuracy: 0.8965 - val_loss: 0.3246 - val_accuracy: 0.9152\n",
            "Epoch 134/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.3812 - accuracy: 0.8969 - val_loss: 0.3229 - val_accuracy: 0.9157\n",
            "Epoch 135/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3794 - accuracy: 0.8972 - val_loss: 0.3213 - val_accuracy: 0.9163\n",
            "Epoch 136/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3776 - accuracy: 0.8976 - val_loss: 0.3197 - val_accuracy: 0.9167\n",
            "Epoch 137/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3759 - accuracy: 0.8979 - val_loss: 0.3181 - val_accuracy: 0.9167\n",
            "Epoch 138/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3742 - accuracy: 0.8982 - val_loss: 0.3166 - val_accuracy: 0.9168\n",
            "Epoch 139/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3725 - accuracy: 0.8986 - val_loss: 0.3150 - val_accuracy: 0.9172\n",
            "Epoch 140/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.3708 - accuracy: 0.8988 - val_loss: 0.3135 - val_accuracy: 0.9172\n",
            "Epoch 141/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3691 - accuracy: 0.8993 - val_loss: 0.3120 - val_accuracy: 0.9172\n",
            "Epoch 142/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3675 - accuracy: 0.8997 - val_loss: 0.3106 - val_accuracy: 0.9173\n",
            "Epoch 143/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3659 - accuracy: 0.9001 - val_loss: 0.3091 - val_accuracy: 0.9175\n",
            "Epoch 144/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3643 - accuracy: 0.9006 - val_loss: 0.3077 - val_accuracy: 0.9182\n",
            "Epoch 145/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3628 - accuracy: 0.9010 - val_loss: 0.3063 - val_accuracy: 0.9190\n",
            "Epoch 146/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.3612 - accuracy: 0.9013 - val_loss: 0.3049 - val_accuracy: 0.9192\n",
            "Epoch 147/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.3597 - accuracy: 0.9016 - val_loss: 0.3036 - val_accuracy: 0.9193\n",
            "Epoch 148/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3582 - accuracy: 0.9020 - val_loss: 0.3022 - val_accuracy: 0.9197\n",
            "Epoch 149/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3567 - accuracy: 0.9023 - val_loss: 0.3009 - val_accuracy: 0.9202\n",
            "Epoch 150/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.3553 - accuracy: 0.9026 - val_loss: 0.2996 - val_accuracy: 0.9203\n",
            "Epoch 151/500\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.3538 - accuracy: 0.9029 - val_loss: 0.2983 - val_accuracy: 0.9207\n",
            "Epoch 152/500\n",
            "422/422 [==============================] - 4s 9ms/step - loss: 0.3524 - accuracy: 0.9032 - val_loss: 0.2970 - val_accuracy: 0.9210\n",
            "Epoch 153/500\n",
            "422/422 [==============================] - 3s 7ms/step - loss: 0.3510 - accuracy: 0.9036 - val_loss: 0.2957 - val_accuracy: 0.9213\n",
            "Epoch 154/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3496 - accuracy: 0.9037 - val_loss: 0.2945 - val_accuracy: 0.9215\n",
            "Epoch 155/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3482 - accuracy: 0.9041 - val_loss: 0.2932 - val_accuracy: 0.9218\n",
            "Epoch 156/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.3468 - accuracy: 0.9044 - val_loss: 0.2920 - val_accuracy: 0.9227\n",
            "Epoch 157/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.3455 - accuracy: 0.9049 - val_loss: 0.2908 - val_accuracy: 0.9225\n",
            "Epoch 158/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3442 - accuracy: 0.9052 - val_loss: 0.2896 - val_accuracy: 0.9230\n",
            "Epoch 159/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3429 - accuracy: 0.9055 - val_loss: 0.2885 - val_accuracy: 0.9232\n",
            "Epoch 160/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3416 - accuracy: 0.9059 - val_loss: 0.2873 - val_accuracy: 0.9235\n",
            "Epoch 161/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3403 - accuracy: 0.9060 - val_loss: 0.2862 - val_accuracy: 0.9237\n",
            "Epoch 162/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3390 - accuracy: 0.9064 - val_loss: 0.2851 - val_accuracy: 0.9238\n",
            "Epoch 163/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.3378 - accuracy: 0.9065 - val_loss: 0.2839 - val_accuracy: 0.9240\n",
            "Epoch 164/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3365 - accuracy: 0.9072 - val_loss: 0.2828 - val_accuracy: 0.9240\n",
            "Epoch 165/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3353 - accuracy: 0.9075 - val_loss: 0.2817 - val_accuracy: 0.9243\n",
            "Epoch 166/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3341 - accuracy: 0.9081 - val_loss: 0.2807 - val_accuracy: 0.9245\n",
            "Epoch 167/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3329 - accuracy: 0.9083 - val_loss: 0.2796 - val_accuracy: 0.9248\n",
            "Epoch 168/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3317 - accuracy: 0.9086 - val_loss: 0.2786 - val_accuracy: 0.9248\n",
            "Epoch 169/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.3305 - accuracy: 0.9088 - val_loss: 0.2775 - val_accuracy: 0.9250\n",
            "Epoch 170/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.3293 - accuracy: 0.9091 - val_loss: 0.2765 - val_accuracy: 0.9253\n",
            "Epoch 171/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3282 - accuracy: 0.9094 - val_loss: 0.2754 - val_accuracy: 0.9253\n",
            "Epoch 172/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3270 - accuracy: 0.9096 - val_loss: 0.2744 - val_accuracy: 0.9253\n",
            "Epoch 173/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3259 - accuracy: 0.9099 - val_loss: 0.2734 - val_accuracy: 0.9258\n",
            "Epoch 174/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3248 - accuracy: 0.9101 - val_loss: 0.2724 - val_accuracy: 0.9258\n",
            "Epoch 175/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3237 - accuracy: 0.9104 - val_loss: 0.2715 - val_accuracy: 0.9260\n",
            "Epoch 176/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.3226 - accuracy: 0.9106 - val_loss: 0.2705 - val_accuracy: 0.9260\n",
            "Epoch 177/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3215 - accuracy: 0.9108 - val_loss: 0.2695 - val_accuracy: 0.9260\n",
            "Epoch 178/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3204 - accuracy: 0.9110 - val_loss: 0.2686 - val_accuracy: 0.9263\n",
            "Epoch 179/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3193 - accuracy: 0.9113 - val_loss: 0.2677 - val_accuracy: 0.9267\n",
            "Epoch 180/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3183 - accuracy: 0.9117 - val_loss: 0.2667 - val_accuracy: 0.9270\n",
            "Epoch 181/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3172 - accuracy: 0.9119 - val_loss: 0.2658 - val_accuracy: 0.9272\n",
            "Epoch 182/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.3162 - accuracy: 0.9123 - val_loss: 0.2649 - val_accuracy: 0.9275\n",
            "Epoch 183/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.3152 - accuracy: 0.9127 - val_loss: 0.2640 - val_accuracy: 0.9280\n",
            "Epoch 184/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3142 - accuracy: 0.9129 - val_loss: 0.2631 - val_accuracy: 0.9283\n",
            "Epoch 185/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3132 - accuracy: 0.9132 - val_loss: 0.2622 - val_accuracy: 0.9287\n",
            "Epoch 186/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3121 - accuracy: 0.9134 - val_loss: 0.2613 - val_accuracy: 0.9288\n",
            "Epoch 187/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3111 - accuracy: 0.9137 - val_loss: 0.2604 - val_accuracy: 0.9288\n",
            "Epoch 188/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.3102 - accuracy: 0.9139 - val_loss: 0.2596 - val_accuracy: 0.9288\n",
            "Epoch 189/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.3092 - accuracy: 0.9142 - val_loss: 0.2587 - val_accuracy: 0.9290\n",
            "Epoch 190/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3082 - accuracy: 0.9144 - val_loss: 0.2579 - val_accuracy: 0.9292\n",
            "Epoch 191/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3073 - accuracy: 0.9146 - val_loss: 0.2571 - val_accuracy: 0.9292\n",
            "Epoch 192/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.3063 - accuracy: 0.9149 - val_loss: 0.2562 - val_accuracy: 0.9292\n",
            "Epoch 193/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3054 - accuracy: 0.9151 - val_loss: 0.2554 - val_accuracy: 0.9292\n",
            "Epoch 194/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3045 - accuracy: 0.9154 - val_loss: 0.2546 - val_accuracy: 0.9293\n",
            "Epoch 195/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.3035 - accuracy: 0.9157 - val_loss: 0.2538 - val_accuracy: 0.9297\n",
            "Epoch 196/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3026 - accuracy: 0.9160 - val_loss: 0.2530 - val_accuracy: 0.9298\n",
            "Epoch 197/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3017 - accuracy: 0.9161 - val_loss: 0.2522 - val_accuracy: 0.9302\n",
            "Epoch 198/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.3008 - accuracy: 0.9164 - val_loss: 0.2514 - val_accuracy: 0.9308\n",
            "Epoch 199/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2999 - accuracy: 0.9167 - val_loss: 0.2507 - val_accuracy: 0.9308\n",
            "Epoch 200/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2991 - accuracy: 0.9170 - val_loss: 0.2499 - val_accuracy: 0.9312\n",
            "Epoch 201/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.2982 - accuracy: 0.9172 - val_loss: 0.2491 - val_accuracy: 0.9313\n",
            "Epoch 202/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2973 - accuracy: 0.9174 - val_loss: 0.2484 - val_accuracy: 0.9313\n",
            "Epoch 203/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2965 - accuracy: 0.9174 - val_loss: 0.2476 - val_accuracy: 0.9317\n",
            "Epoch 204/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2956 - accuracy: 0.9177 - val_loss: 0.2469 - val_accuracy: 0.9320\n",
            "Epoch 205/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2947 - accuracy: 0.9178 - val_loss: 0.2461 - val_accuracy: 0.9322\n",
            "Epoch 206/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2939 - accuracy: 0.9180 - val_loss: 0.2454 - val_accuracy: 0.9325\n",
            "Epoch 207/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2931 - accuracy: 0.9181 - val_loss: 0.2447 - val_accuracy: 0.9327\n",
            "Epoch 208/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2923 - accuracy: 0.9183 - val_loss: 0.2440 - val_accuracy: 0.9332\n",
            "Epoch 209/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2914 - accuracy: 0.9186 - val_loss: 0.2433 - val_accuracy: 0.9332\n",
            "Epoch 210/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2906 - accuracy: 0.9188 - val_loss: 0.2426 - val_accuracy: 0.9332\n",
            "Epoch 211/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2898 - accuracy: 0.9189 - val_loss: 0.2419 - val_accuracy: 0.9333\n",
            "Epoch 212/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2890 - accuracy: 0.9190 - val_loss: 0.2412 - val_accuracy: 0.9335\n",
            "Epoch 213/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2882 - accuracy: 0.9192 - val_loss: 0.2405 - val_accuracy: 0.9337\n",
            "Epoch 214/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.2874 - accuracy: 0.9194 - val_loss: 0.2398 - val_accuracy: 0.9338\n",
            "Epoch 215/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2866 - accuracy: 0.9195 - val_loss: 0.2391 - val_accuracy: 0.9343\n",
            "Epoch 216/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2859 - accuracy: 0.9198 - val_loss: 0.2384 - val_accuracy: 0.9343\n",
            "Epoch 217/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2851 - accuracy: 0.9200 - val_loss: 0.2378 - val_accuracy: 0.9342\n",
            "Epoch 218/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2843 - accuracy: 0.9202 - val_loss: 0.2371 - val_accuracy: 0.9347\n",
            "Epoch 219/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2836 - accuracy: 0.9205 - val_loss: 0.2364 - val_accuracy: 0.9347\n",
            "Epoch 220/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2828 - accuracy: 0.9206 - val_loss: 0.2358 - val_accuracy: 0.9347\n",
            "Epoch 221/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2820 - accuracy: 0.9208 - val_loss: 0.2351 - val_accuracy: 0.9347\n",
            "Epoch 222/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2813 - accuracy: 0.9212 - val_loss: 0.2345 - val_accuracy: 0.9345\n",
            "Epoch 223/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2806 - accuracy: 0.9213 - val_loss: 0.2338 - val_accuracy: 0.9345\n",
            "Epoch 224/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2798 - accuracy: 0.9215 - val_loss: 0.2332 - val_accuracy: 0.9348\n",
            "Epoch 225/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2791 - accuracy: 0.9216 - val_loss: 0.2326 - val_accuracy: 0.9348\n",
            "Epoch 226/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2784 - accuracy: 0.9217 - val_loss: 0.2319 - val_accuracy: 0.9348\n",
            "Epoch 227/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2776 - accuracy: 0.9219 - val_loss: 0.2313 - val_accuracy: 0.9348\n",
            "Epoch 228/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2769 - accuracy: 0.9222 - val_loss: 0.2307 - val_accuracy: 0.9350\n",
            "Epoch 229/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2762 - accuracy: 0.9223 - val_loss: 0.2301 - val_accuracy: 0.9350\n",
            "Epoch 230/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2755 - accuracy: 0.9225 - val_loss: 0.2295 - val_accuracy: 0.9352\n",
            "Epoch 231/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2748 - accuracy: 0.9225 - val_loss: 0.2289 - val_accuracy: 0.9353\n",
            "Epoch 232/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2741 - accuracy: 0.9227 - val_loss: 0.2283 - val_accuracy: 0.9357\n",
            "Epoch 233/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.2734 - accuracy: 0.9230 - val_loss: 0.2277 - val_accuracy: 0.9357\n",
            "Epoch 234/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2727 - accuracy: 0.9231 - val_loss: 0.2271 - val_accuracy: 0.9358\n",
            "Epoch 235/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2721 - accuracy: 0.9233 - val_loss: 0.2265 - val_accuracy: 0.9358\n",
            "Epoch 236/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2714 - accuracy: 0.9233 - val_loss: 0.2259 - val_accuracy: 0.9357\n",
            "Epoch 237/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2707 - accuracy: 0.9235 - val_loss: 0.2253 - val_accuracy: 0.9358\n",
            "Epoch 238/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2700 - accuracy: 0.9236 - val_loss: 0.2247 - val_accuracy: 0.9358\n",
            "Epoch 239/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2694 - accuracy: 0.9239 - val_loss: 0.2242 - val_accuracy: 0.9358\n",
            "Epoch 240/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2687 - accuracy: 0.9240 - val_loss: 0.2236 - val_accuracy: 0.9358\n",
            "Epoch 241/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2680 - accuracy: 0.9240 - val_loss: 0.2230 - val_accuracy: 0.9358\n",
            "Epoch 242/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2674 - accuracy: 0.9243 - val_loss: 0.2225 - val_accuracy: 0.9360\n",
            "Epoch 243/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2667 - accuracy: 0.9245 - val_loss: 0.2219 - val_accuracy: 0.9362\n",
            "Epoch 244/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2661 - accuracy: 0.9246 - val_loss: 0.2214 - val_accuracy: 0.9363\n",
            "Epoch 245/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2655 - accuracy: 0.9247 - val_loss: 0.2208 - val_accuracy: 0.9363\n",
            "Epoch 246/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2648 - accuracy: 0.9249 - val_loss: 0.2203 - val_accuracy: 0.9363\n",
            "Epoch 247/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2642 - accuracy: 0.9249 - val_loss: 0.2197 - val_accuracy: 0.9368\n",
            "Epoch 248/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2636 - accuracy: 0.9251 - val_loss: 0.2192 - val_accuracy: 0.9368\n",
            "Epoch 249/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2630 - accuracy: 0.9253 - val_loss: 0.2187 - val_accuracy: 0.9372\n",
            "Epoch 250/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2623 - accuracy: 0.9254 - val_loss: 0.2181 - val_accuracy: 0.9373\n",
            "Epoch 251/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2617 - accuracy: 0.9257 - val_loss: 0.2176 - val_accuracy: 0.9373\n",
            "Epoch 252/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.2611 - accuracy: 0.9257 - val_loss: 0.2171 - val_accuracy: 0.9375\n",
            "Epoch 253/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2605 - accuracy: 0.9259 - val_loss: 0.2165 - val_accuracy: 0.9380\n",
            "Epoch 254/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2599 - accuracy: 0.9262 - val_loss: 0.2160 - val_accuracy: 0.9382\n",
            "Epoch 255/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2593 - accuracy: 0.9264 - val_loss: 0.2155 - val_accuracy: 0.9380\n",
            "Epoch 256/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2587 - accuracy: 0.9265 - val_loss: 0.2150 - val_accuracy: 0.9382\n",
            "Epoch 257/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2581 - accuracy: 0.9267 - val_loss: 0.2145 - val_accuracy: 0.9382\n",
            "Epoch 258/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2575 - accuracy: 0.9269 - val_loss: 0.2140 - val_accuracy: 0.9382\n",
            "Epoch 259/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2569 - accuracy: 0.9270 - val_loss: 0.2135 - val_accuracy: 0.9385\n",
            "Epoch 260/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2563 - accuracy: 0.9270 - val_loss: 0.2130 - val_accuracy: 0.9385\n",
            "Epoch 261/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2558 - accuracy: 0.9274 - val_loss: 0.2125 - val_accuracy: 0.9387\n",
            "Epoch 262/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2552 - accuracy: 0.9275 - val_loss: 0.2120 - val_accuracy: 0.9387\n",
            "Epoch 263/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2546 - accuracy: 0.9278 - val_loss: 0.2115 - val_accuracy: 0.9388\n",
            "Epoch 264/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2540 - accuracy: 0.9279 - val_loss: 0.2110 - val_accuracy: 0.9390\n",
            "Epoch 265/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.2535 - accuracy: 0.9279 - val_loss: 0.2105 - val_accuracy: 0.9392\n",
            "Epoch 266/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2529 - accuracy: 0.9281 - val_loss: 0.2100 - val_accuracy: 0.9392\n",
            "Epoch 267/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2523 - accuracy: 0.9282 - val_loss: 0.2095 - val_accuracy: 0.9395\n",
            "Epoch 268/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2518 - accuracy: 0.9284 - val_loss: 0.2091 - val_accuracy: 0.9403\n",
            "Epoch 269/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2512 - accuracy: 0.9284 - val_loss: 0.2086 - val_accuracy: 0.9403\n",
            "Epoch 270/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2507 - accuracy: 0.9286 - val_loss: 0.2081 - val_accuracy: 0.9405\n",
            "Epoch 271/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2501 - accuracy: 0.9286 - val_loss: 0.2077 - val_accuracy: 0.9407\n",
            "Epoch 272/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2496 - accuracy: 0.9287 - val_loss: 0.2072 - val_accuracy: 0.9408\n",
            "Epoch 273/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2490 - accuracy: 0.9289 - val_loss: 0.2067 - val_accuracy: 0.9410\n",
            "Epoch 274/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2485 - accuracy: 0.9291 - val_loss: 0.2063 - val_accuracy: 0.9410\n",
            "Epoch 275/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2480 - accuracy: 0.9293 - val_loss: 0.2058 - val_accuracy: 0.9410\n",
            "Epoch 276/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2474 - accuracy: 0.9294 - val_loss: 0.2053 - val_accuracy: 0.9412\n",
            "Epoch 277/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.2469 - accuracy: 0.9295 - val_loss: 0.2049 - val_accuracy: 0.9413\n",
            "Epoch 278/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2464 - accuracy: 0.9296 - val_loss: 0.2044 - val_accuracy: 0.9413\n",
            "Epoch 279/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2458 - accuracy: 0.9297 - val_loss: 0.2040 - val_accuracy: 0.9417\n",
            "Epoch 280/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2453 - accuracy: 0.9299 - val_loss: 0.2036 - val_accuracy: 0.9412\n",
            "Epoch 281/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2448 - accuracy: 0.9299 - val_loss: 0.2031 - val_accuracy: 0.9413\n",
            "Epoch 282/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2443 - accuracy: 0.9300 - val_loss: 0.2027 - val_accuracy: 0.9413\n",
            "Epoch 283/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2438 - accuracy: 0.9302 - val_loss: 0.2022 - val_accuracy: 0.9415\n",
            "Epoch 284/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2433 - accuracy: 0.9303 - val_loss: 0.2018 - val_accuracy: 0.9415\n",
            "Epoch 285/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2428 - accuracy: 0.9304 - val_loss: 0.2014 - val_accuracy: 0.9415\n",
            "Epoch 286/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2422 - accuracy: 0.9308 - val_loss: 0.2009 - val_accuracy: 0.9417\n",
            "Epoch 287/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2417 - accuracy: 0.9307 - val_loss: 0.2005 - val_accuracy: 0.9417\n",
            "Epoch 288/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2412 - accuracy: 0.9309 - val_loss: 0.2001 - val_accuracy: 0.9417\n",
            "Epoch 289/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2407 - accuracy: 0.9310 - val_loss: 0.1996 - val_accuracy: 0.9417\n",
            "Epoch 290/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2403 - accuracy: 0.9311 - val_loss: 0.1992 - val_accuracy: 0.9418\n",
            "Epoch 291/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2398 - accuracy: 0.9313 - val_loss: 0.1988 - val_accuracy: 0.9418\n",
            "Epoch 292/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2393 - accuracy: 0.9314 - val_loss: 0.1984 - val_accuracy: 0.9418\n",
            "Epoch 293/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2388 - accuracy: 0.9315 - val_loss: 0.1980 - val_accuracy: 0.9420\n",
            "Epoch 294/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2383 - accuracy: 0.9318 - val_loss: 0.1976 - val_accuracy: 0.9420\n",
            "Epoch 295/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2378 - accuracy: 0.9321 - val_loss: 0.1971 - val_accuracy: 0.9422\n",
            "Epoch 296/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2373 - accuracy: 0.9321 - val_loss: 0.1967 - val_accuracy: 0.9423\n",
            "Epoch 297/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2368 - accuracy: 0.9322 - val_loss: 0.1963 - val_accuracy: 0.9423\n",
            "Epoch 298/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2364 - accuracy: 0.9324 - val_loss: 0.1959 - val_accuracy: 0.9423\n",
            "Epoch 299/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2359 - accuracy: 0.9326 - val_loss: 0.1955 - val_accuracy: 0.9425\n",
            "Epoch 300/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2354 - accuracy: 0.9328 - val_loss: 0.1951 - val_accuracy: 0.9427\n",
            "Epoch 301/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2349 - accuracy: 0.9329 - val_loss: 0.1947 - val_accuracy: 0.9427\n",
            "Epoch 302/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2345 - accuracy: 0.9330 - val_loss: 0.1943 - val_accuracy: 0.9428\n",
            "Epoch 303/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2340 - accuracy: 0.9331 - val_loss: 0.1939 - val_accuracy: 0.9428\n",
            "Epoch 304/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2336 - accuracy: 0.9331 - val_loss: 0.1935 - val_accuracy: 0.9428\n",
            "Epoch 305/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2331 - accuracy: 0.9332 - val_loss: 0.1931 - val_accuracy: 0.9430\n",
            "Epoch 306/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2326 - accuracy: 0.9334 - val_loss: 0.1927 - val_accuracy: 0.9430\n",
            "Epoch 307/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2322 - accuracy: 0.9334 - val_loss: 0.1923 - val_accuracy: 0.9430\n",
            "Epoch 308/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.2317 - accuracy: 0.9335 - val_loss: 0.1920 - val_accuracy: 0.9430\n",
            "Epoch 309/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2313 - accuracy: 0.9337 - val_loss: 0.1916 - val_accuracy: 0.9430\n",
            "Epoch 310/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2308 - accuracy: 0.9337 - val_loss: 0.1912 - val_accuracy: 0.9430\n",
            "Epoch 311/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2304 - accuracy: 0.9339 - val_loss: 0.1908 - val_accuracy: 0.9432\n",
            "Epoch 312/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2299 - accuracy: 0.9340 - val_loss: 0.1904 - val_accuracy: 0.9432\n",
            "Epoch 313/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2295 - accuracy: 0.9341 - val_loss: 0.1901 - val_accuracy: 0.9433\n",
            "Epoch 314/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.2290 - accuracy: 0.9343 - val_loss: 0.1897 - val_accuracy: 0.9435\n",
            "Epoch 315/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2286 - accuracy: 0.9345 - val_loss: 0.1893 - val_accuracy: 0.9437\n",
            "Epoch 316/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2282 - accuracy: 0.9347 - val_loss: 0.1889 - val_accuracy: 0.9438\n",
            "Epoch 317/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2277 - accuracy: 0.9347 - val_loss: 0.1886 - val_accuracy: 0.9440\n",
            "Epoch 318/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2273 - accuracy: 0.9350 - val_loss: 0.1882 - val_accuracy: 0.9440\n",
            "Epoch 319/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2269 - accuracy: 0.9349 - val_loss: 0.1878 - val_accuracy: 0.9442\n",
            "Epoch 320/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.2264 - accuracy: 0.9351 - val_loss: 0.1875 - val_accuracy: 0.9443\n",
            "Epoch 321/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2260 - accuracy: 0.9352 - val_loss: 0.1871 - val_accuracy: 0.9450\n",
            "Epoch 322/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2256 - accuracy: 0.9353 - val_loss: 0.1868 - val_accuracy: 0.9450\n",
            "Epoch 323/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2252 - accuracy: 0.9355 - val_loss: 0.1864 - val_accuracy: 0.9452\n",
            "Epoch 324/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2248 - accuracy: 0.9356 - val_loss: 0.1860 - val_accuracy: 0.9452\n",
            "Epoch 325/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2243 - accuracy: 0.9359 - val_loss: 0.1857 - val_accuracy: 0.9452\n",
            "Epoch 326/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2239 - accuracy: 0.9359 - val_loss: 0.1853 - val_accuracy: 0.9453\n",
            "Epoch 327/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2235 - accuracy: 0.9360 - val_loss: 0.1850 - val_accuracy: 0.9453\n",
            "Epoch 328/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2231 - accuracy: 0.9361 - val_loss: 0.1846 - val_accuracy: 0.9455\n",
            "Epoch 329/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2227 - accuracy: 0.9362 - val_loss: 0.1843 - val_accuracy: 0.9457\n",
            "Epoch 330/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2223 - accuracy: 0.9364 - val_loss: 0.1839 - val_accuracy: 0.9457\n",
            "Epoch 331/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2219 - accuracy: 0.9364 - val_loss: 0.1836 - val_accuracy: 0.9460\n",
            "Epoch 332/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2215 - accuracy: 0.9365 - val_loss: 0.1833 - val_accuracy: 0.9462\n",
            "Epoch 333/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2211 - accuracy: 0.9366 - val_loss: 0.1829 - val_accuracy: 0.9463\n",
            "Epoch 334/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2207 - accuracy: 0.9367 - val_loss: 0.1826 - val_accuracy: 0.9463\n",
            "Epoch 335/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2203 - accuracy: 0.9369 - val_loss: 0.1823 - val_accuracy: 0.9465\n",
            "Epoch 336/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2199 - accuracy: 0.9369 - val_loss: 0.1819 - val_accuracy: 0.9465\n",
            "Epoch 337/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2195 - accuracy: 0.9370 - val_loss: 0.1816 - val_accuracy: 0.9472\n",
            "Epoch 338/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2191 - accuracy: 0.9371 - val_loss: 0.1812 - val_accuracy: 0.9472\n",
            "Epoch 339/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.2187 - accuracy: 0.9373 - val_loss: 0.1809 - val_accuracy: 0.9473\n",
            "Epoch 340/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2183 - accuracy: 0.9373 - val_loss: 0.1806 - val_accuracy: 0.9475\n",
            "Epoch 341/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2179 - accuracy: 0.9375 - val_loss: 0.1803 - val_accuracy: 0.9475\n",
            "Epoch 342/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2175 - accuracy: 0.9376 - val_loss: 0.1799 - val_accuracy: 0.9475\n",
            "Epoch 343/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2172 - accuracy: 0.9376 - val_loss: 0.1796 - val_accuracy: 0.9475\n",
            "Epoch 344/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2168 - accuracy: 0.9377 - val_loss: 0.1793 - val_accuracy: 0.9477\n",
            "Epoch 345/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.2164 - accuracy: 0.9378 - val_loss: 0.1790 - val_accuracy: 0.9478\n",
            "Epoch 346/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2160 - accuracy: 0.9379 - val_loss: 0.1787 - val_accuracy: 0.9478\n",
            "Epoch 347/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2156 - accuracy: 0.9380 - val_loss: 0.1783 - val_accuracy: 0.9478\n",
            "Epoch 348/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2153 - accuracy: 0.9381 - val_loss: 0.1780 - val_accuracy: 0.9482\n",
            "Epoch 349/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2149 - accuracy: 0.9382 - val_loss: 0.1777 - val_accuracy: 0.9482\n",
            "Epoch 350/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2145 - accuracy: 0.9382 - val_loss: 0.1774 - val_accuracy: 0.9482\n",
            "Epoch 351/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2141 - accuracy: 0.9384 - val_loss: 0.1771 - val_accuracy: 0.9483\n",
            "Epoch 352/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2138 - accuracy: 0.9384 - val_loss: 0.1768 - val_accuracy: 0.9483\n",
            "Epoch 353/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2134 - accuracy: 0.9385 - val_loss: 0.1765 - val_accuracy: 0.9485\n",
            "Epoch 354/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2130 - accuracy: 0.9385 - val_loss: 0.1761 - val_accuracy: 0.9487\n",
            "Epoch 355/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2127 - accuracy: 0.9387 - val_loss: 0.1758 - val_accuracy: 0.9485\n",
            "Epoch 356/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2123 - accuracy: 0.9388 - val_loss: 0.1755 - val_accuracy: 0.9487\n",
            "Epoch 357/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2119 - accuracy: 0.9390 - val_loss: 0.1752 - val_accuracy: 0.9487\n",
            "Epoch 358/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2116 - accuracy: 0.9390 - val_loss: 0.1749 - val_accuracy: 0.9490\n",
            "Epoch 359/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2112 - accuracy: 0.9391 - val_loss: 0.1746 - val_accuracy: 0.9490\n",
            "Epoch 360/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2109 - accuracy: 0.9392 - val_loss: 0.1743 - val_accuracy: 0.9490\n",
            "Epoch 361/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2105 - accuracy: 0.9393 - val_loss: 0.1740 - val_accuracy: 0.9490\n",
            "Epoch 362/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2102 - accuracy: 0.9394 - val_loss: 0.1737 - val_accuracy: 0.9490\n",
            "Epoch 363/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2098 - accuracy: 0.9394 - val_loss: 0.1734 - val_accuracy: 0.9492\n",
            "Epoch 364/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.2094 - accuracy: 0.9395 - val_loss: 0.1731 - val_accuracy: 0.9493\n",
            "Epoch 365/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2091 - accuracy: 0.9397 - val_loss: 0.1728 - val_accuracy: 0.9493\n",
            "Epoch 366/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2087 - accuracy: 0.9398 - val_loss: 0.1725 - val_accuracy: 0.9493\n",
            "Epoch 367/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2084 - accuracy: 0.9399 - val_loss: 0.1723 - val_accuracy: 0.9493\n",
            "Epoch 368/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2081 - accuracy: 0.9400 - val_loss: 0.1720 - val_accuracy: 0.9495\n",
            "Epoch 369/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2077 - accuracy: 0.9400 - val_loss: 0.1717 - val_accuracy: 0.9497\n",
            "Epoch 370/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2074 - accuracy: 0.9401 - val_loss: 0.1714 - val_accuracy: 0.9498\n",
            "Epoch 371/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2070 - accuracy: 0.9402 - val_loss: 0.1711 - val_accuracy: 0.9498\n",
            "Epoch 372/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2067 - accuracy: 0.9403 - val_loss: 0.1708 - val_accuracy: 0.9498\n",
            "Epoch 373/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2063 - accuracy: 0.9404 - val_loss: 0.1705 - val_accuracy: 0.9498\n",
            "Epoch 374/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2060 - accuracy: 0.9404 - val_loss: 0.1703 - val_accuracy: 0.9498\n",
            "Epoch 375/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2057 - accuracy: 0.9406 - val_loss: 0.1700 - val_accuracy: 0.9500\n",
            "Epoch 376/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2053 - accuracy: 0.9407 - val_loss: 0.1697 - val_accuracy: 0.9500\n",
            "Epoch 377/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2050 - accuracy: 0.9408 - val_loss: 0.1694 - val_accuracy: 0.9503\n",
            "Epoch 378/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2047 - accuracy: 0.9409 - val_loss: 0.1691 - val_accuracy: 0.9503\n",
            "Epoch 379/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2044 - accuracy: 0.9410 - val_loss: 0.1689 - val_accuracy: 0.9503\n",
            "Epoch 380/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2040 - accuracy: 0.9410 - val_loss: 0.1686 - val_accuracy: 0.9505\n",
            "Epoch 381/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2037 - accuracy: 0.9411 - val_loss: 0.1683 - val_accuracy: 0.9505\n",
            "Epoch 382/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2034 - accuracy: 0.9411 - val_loss: 0.1681 - val_accuracy: 0.9505\n",
            "Epoch 383/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.2030 - accuracy: 0.9411 - val_loss: 0.1678 - val_accuracy: 0.9507\n",
            "Epoch 384/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2027 - accuracy: 0.9412 - val_loss: 0.1675 - val_accuracy: 0.9507\n",
            "Epoch 385/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2024 - accuracy: 0.9413 - val_loss: 0.1672 - val_accuracy: 0.9508\n",
            "Epoch 386/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2021 - accuracy: 0.9414 - val_loss: 0.1670 - val_accuracy: 0.9512\n",
            "Epoch 387/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2017 - accuracy: 0.9416 - val_loss: 0.1667 - val_accuracy: 0.9512\n",
            "Epoch 388/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2014 - accuracy: 0.9416 - val_loss: 0.1664 - val_accuracy: 0.9512\n",
            "Epoch 389/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.2011 - accuracy: 0.9416 - val_loss: 0.1662 - val_accuracy: 0.9513\n",
            "Epoch 390/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2008 - accuracy: 0.9418 - val_loss: 0.1659 - val_accuracy: 0.9513\n",
            "Epoch 391/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2005 - accuracy: 0.9417 - val_loss: 0.1656 - val_accuracy: 0.9513\n",
            "Epoch 392/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.2002 - accuracy: 0.9419 - val_loss: 0.1654 - val_accuracy: 0.9515\n",
            "Epoch 393/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1998 - accuracy: 0.9419 - val_loss: 0.1651 - val_accuracy: 0.9520\n",
            "Epoch 394/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1995 - accuracy: 0.9420 - val_loss: 0.1649 - val_accuracy: 0.9522\n",
            "Epoch 395/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1992 - accuracy: 0.9421 - val_loss: 0.1646 - val_accuracy: 0.9523\n",
            "Epoch 396/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1989 - accuracy: 0.9422 - val_loss: 0.1643 - val_accuracy: 0.9523\n",
            "Epoch 397/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1986 - accuracy: 0.9424 - val_loss: 0.1641 - val_accuracy: 0.9523\n",
            "Epoch 398/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1983 - accuracy: 0.9424 - val_loss: 0.1638 - val_accuracy: 0.9527\n",
            "Epoch 399/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1980 - accuracy: 0.9424 - val_loss: 0.1636 - val_accuracy: 0.9528\n",
            "Epoch 400/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1977 - accuracy: 0.9425 - val_loss: 0.1633 - val_accuracy: 0.9530\n",
            "Epoch 401/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1974 - accuracy: 0.9426 - val_loss: 0.1631 - val_accuracy: 0.9532\n",
            "Epoch 402/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1971 - accuracy: 0.9427 - val_loss: 0.1628 - val_accuracy: 0.9532\n",
            "Epoch 403/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1968 - accuracy: 0.9429 - val_loss: 0.1626 - val_accuracy: 0.9535\n",
            "Epoch 404/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1965 - accuracy: 0.9430 - val_loss: 0.1623 - val_accuracy: 0.9533\n",
            "Epoch 405/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1962 - accuracy: 0.9431 - val_loss: 0.1621 - val_accuracy: 0.9537\n",
            "Epoch 406/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1959 - accuracy: 0.9432 - val_loss: 0.1618 - val_accuracy: 0.9537\n",
            "Epoch 407/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1956 - accuracy: 0.9432 - val_loss: 0.1616 - val_accuracy: 0.9537\n",
            "Epoch 408/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.1953 - accuracy: 0.9433 - val_loss: 0.1613 - val_accuracy: 0.9540\n",
            "Epoch 409/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1950 - accuracy: 0.9434 - val_loss: 0.1611 - val_accuracy: 0.9540\n",
            "Epoch 410/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1947 - accuracy: 0.9434 - val_loss: 0.1608 - val_accuracy: 0.9542\n",
            "Epoch 411/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1944 - accuracy: 0.9436 - val_loss: 0.1606 - val_accuracy: 0.9543\n",
            "Epoch 412/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1941 - accuracy: 0.9438 - val_loss: 0.1603 - val_accuracy: 0.9545\n",
            "Epoch 413/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1938 - accuracy: 0.9438 - val_loss: 0.1601 - val_accuracy: 0.9545\n",
            "Epoch 414/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1935 - accuracy: 0.9438 - val_loss: 0.1599 - val_accuracy: 0.9545\n",
            "Epoch 415/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1932 - accuracy: 0.9439 - val_loss: 0.1596 - val_accuracy: 0.9545\n",
            "Epoch 416/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1929 - accuracy: 0.9440 - val_loss: 0.1594 - val_accuracy: 0.9545\n",
            "Epoch 417/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1927 - accuracy: 0.9440 - val_loss: 0.1591 - val_accuracy: 0.9545\n",
            "Epoch 418/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1924 - accuracy: 0.9441 - val_loss: 0.1589 - val_accuracy: 0.9547\n",
            "Epoch 419/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1921 - accuracy: 0.9442 - val_loss: 0.1587 - val_accuracy: 0.9545\n",
            "Epoch 420/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1918 - accuracy: 0.9443 - val_loss: 0.1584 - val_accuracy: 0.9547\n",
            "Epoch 421/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1915 - accuracy: 0.9442 - val_loss: 0.1582 - val_accuracy: 0.9547\n",
            "Epoch 422/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1912 - accuracy: 0.9443 - val_loss: 0.1580 - val_accuracy: 0.9547\n",
            "Epoch 423/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1910 - accuracy: 0.9445 - val_loss: 0.1577 - val_accuracy: 0.9545\n",
            "Epoch 424/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1907 - accuracy: 0.9446 - val_loss: 0.1575 - val_accuracy: 0.9547\n",
            "Epoch 425/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1904 - accuracy: 0.9448 - val_loss: 0.1573 - val_accuracy: 0.9547\n",
            "Epoch 426/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1901 - accuracy: 0.9449 - val_loss: 0.1570 - val_accuracy: 0.9550\n",
            "Epoch 427/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1899 - accuracy: 0.9449 - val_loss: 0.1568 - val_accuracy: 0.9548\n",
            "Epoch 428/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1896 - accuracy: 0.9450 - val_loss: 0.1566 - val_accuracy: 0.9548\n",
            "Epoch 429/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1893 - accuracy: 0.9451 - val_loss: 0.1564 - val_accuracy: 0.9550\n",
            "Epoch 430/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1890 - accuracy: 0.9452 - val_loss: 0.1561 - val_accuracy: 0.9552\n",
            "Epoch 431/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1888 - accuracy: 0.9453 - val_loss: 0.1559 - val_accuracy: 0.9552\n",
            "Epoch 432/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1885 - accuracy: 0.9454 - val_loss: 0.1557 - val_accuracy: 0.9552\n",
            "Epoch 433/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.1882 - accuracy: 0.9455 - val_loss: 0.1555 - val_accuracy: 0.9553\n",
            "Epoch 434/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1879 - accuracy: 0.9455 - val_loss: 0.1552 - val_accuracy: 0.9553\n",
            "Epoch 435/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1877 - accuracy: 0.9456 - val_loss: 0.1550 - val_accuracy: 0.9553\n",
            "Epoch 436/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1874 - accuracy: 0.9457 - val_loss: 0.1548 - val_accuracy: 0.9555\n",
            "Epoch 437/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1871 - accuracy: 0.9457 - val_loss: 0.1546 - val_accuracy: 0.9557\n",
            "Epoch 438/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1869 - accuracy: 0.9458 - val_loss: 0.1544 - val_accuracy: 0.9562\n",
            "Epoch 439/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1866 - accuracy: 0.9459 - val_loss: 0.1541 - val_accuracy: 0.9562\n",
            "Epoch 440/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1864 - accuracy: 0.9461 - val_loss: 0.1539 - val_accuracy: 0.9563\n",
            "Epoch 441/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1861 - accuracy: 0.9462 - val_loss: 0.1537 - val_accuracy: 0.9567\n",
            "Epoch 442/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1858 - accuracy: 0.9463 - val_loss: 0.1535 - val_accuracy: 0.9567\n",
            "Epoch 443/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1856 - accuracy: 0.9464 - val_loss: 0.1533 - val_accuracy: 0.9568\n",
            "Epoch 444/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1853 - accuracy: 0.9465 - val_loss: 0.1531 - val_accuracy: 0.9567\n",
            "Epoch 445/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1851 - accuracy: 0.9465 - val_loss: 0.1529 - val_accuracy: 0.9570\n",
            "Epoch 446/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1848 - accuracy: 0.9467 - val_loss: 0.1526 - val_accuracy: 0.9568\n",
            "Epoch 447/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1845 - accuracy: 0.9466 - val_loss: 0.1524 - val_accuracy: 0.9572\n",
            "Epoch 448/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1843 - accuracy: 0.9467 - val_loss: 0.1522 - val_accuracy: 0.9572\n",
            "Epoch 449/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1840 - accuracy: 0.9469 - val_loss: 0.1520 - val_accuracy: 0.9573\n",
            "Epoch 450/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1838 - accuracy: 0.9469 - val_loss: 0.1518 - val_accuracy: 0.9573\n",
            "Epoch 451/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1835 - accuracy: 0.9470 - val_loss: 0.1516 - val_accuracy: 0.9577\n",
            "Epoch 452/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.1833 - accuracy: 0.9471 - val_loss: 0.1514 - val_accuracy: 0.9578\n",
            "Epoch 453/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1830 - accuracy: 0.9471 - val_loss: 0.1512 - val_accuracy: 0.9578\n",
            "Epoch 454/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1828 - accuracy: 0.9471 - val_loss: 0.1510 - val_accuracy: 0.9578\n",
            "Epoch 455/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1825 - accuracy: 0.9473 - val_loss: 0.1508 - val_accuracy: 0.9582\n",
            "Epoch 456/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1823 - accuracy: 0.9473 - val_loss: 0.1506 - val_accuracy: 0.9583\n",
            "Epoch 457/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1820 - accuracy: 0.9474 - val_loss: 0.1503 - val_accuracy: 0.9583\n",
            "Epoch 458/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1818 - accuracy: 0.9476 - val_loss: 0.1501 - val_accuracy: 0.9583\n",
            "Epoch 459/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1815 - accuracy: 0.9476 - val_loss: 0.1499 - val_accuracy: 0.9583\n",
            "Epoch 460/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1813 - accuracy: 0.9476 - val_loss: 0.1497 - val_accuracy: 0.9585\n",
            "Epoch 461/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1810 - accuracy: 0.9479 - val_loss: 0.1495 - val_accuracy: 0.9588\n",
            "Epoch 462/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1808 - accuracy: 0.9479 - val_loss: 0.1493 - val_accuracy: 0.9592\n",
            "Epoch 463/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1805 - accuracy: 0.9479 - val_loss: 0.1491 - val_accuracy: 0.9592\n",
            "Epoch 464/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1803 - accuracy: 0.9480 - val_loss: 0.1489 - val_accuracy: 0.9592\n",
            "Epoch 465/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1801 - accuracy: 0.9481 - val_loss: 0.1487 - val_accuracy: 0.9592\n",
            "Epoch 466/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1798 - accuracy: 0.9482 - val_loss: 0.1485 - val_accuracy: 0.9593\n",
            "Epoch 467/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1796 - accuracy: 0.9482 - val_loss: 0.1484 - val_accuracy: 0.9593\n",
            "Epoch 468/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1793 - accuracy: 0.9483 - val_loss: 0.1482 - val_accuracy: 0.9592\n",
            "Epoch 469/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1791 - accuracy: 0.9484 - val_loss: 0.1480 - val_accuracy: 0.9592\n",
            "Epoch 470/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1789 - accuracy: 0.9484 - val_loss: 0.1478 - val_accuracy: 0.9592\n",
            "Epoch 471/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1786 - accuracy: 0.9486 - val_loss: 0.1476 - val_accuracy: 0.9593\n",
            "Epoch 472/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1784 - accuracy: 0.9486 - val_loss: 0.1474 - val_accuracy: 0.9593\n",
            "Epoch 473/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1782 - accuracy: 0.9487 - val_loss: 0.1472 - val_accuracy: 0.9595\n",
            "Epoch 474/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1779 - accuracy: 0.9488 - val_loss: 0.1470 - val_accuracy: 0.9595\n",
            "Epoch 475/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1777 - accuracy: 0.9488 - val_loss: 0.1468 - val_accuracy: 0.9595\n",
            "Epoch 476/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1775 - accuracy: 0.9488 - val_loss: 0.1466 - val_accuracy: 0.9593\n",
            "Epoch 477/500\n",
            "422/422 [==============================] - 2s 6ms/step - loss: 0.1772 - accuracy: 0.9489 - val_loss: 0.1464 - val_accuracy: 0.9595\n",
            "Epoch 478/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1770 - accuracy: 0.9489 - val_loss: 0.1462 - val_accuracy: 0.9597\n",
            "Epoch 479/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1768 - accuracy: 0.9490 - val_loss: 0.1461 - val_accuracy: 0.9598\n",
            "Epoch 480/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1765 - accuracy: 0.9490 - val_loss: 0.1459 - val_accuracy: 0.9598\n",
            "Epoch 481/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1763 - accuracy: 0.9491 - val_loss: 0.1457 - val_accuracy: 0.9602\n",
            "Epoch 482/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1761 - accuracy: 0.9492 - val_loss: 0.1455 - val_accuracy: 0.9602\n",
            "Epoch 483/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1758 - accuracy: 0.9491 - val_loss: 0.1453 - val_accuracy: 0.9603\n",
            "Epoch 484/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1756 - accuracy: 0.9493 - val_loss: 0.1451 - val_accuracy: 0.9605\n",
            "Epoch 485/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1754 - accuracy: 0.9494 - val_loss: 0.1449 - val_accuracy: 0.9607\n",
            "Epoch 486/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1752 - accuracy: 0.9494 - val_loss: 0.1448 - val_accuracy: 0.9605\n",
            "Epoch 487/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1749 - accuracy: 0.9496 - val_loss: 0.1446 - val_accuracy: 0.9607\n",
            "Epoch 488/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1747 - accuracy: 0.9496 - val_loss: 0.1444 - val_accuracy: 0.9607\n",
            "Epoch 489/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1745 - accuracy: 0.9497 - val_loss: 0.1442 - val_accuracy: 0.9607\n",
            "Epoch 490/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1743 - accuracy: 0.9496 - val_loss: 0.1440 - val_accuracy: 0.9607\n",
            "Epoch 491/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1741 - accuracy: 0.9498 - val_loss: 0.1439 - val_accuracy: 0.9607\n",
            "Epoch 492/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1738 - accuracy: 0.9499 - val_loss: 0.1437 - val_accuracy: 0.9608\n",
            "Epoch 493/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1736 - accuracy: 0.9499 - val_loss: 0.1435 - val_accuracy: 0.9608\n",
            "Epoch 494/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1734 - accuracy: 0.9500 - val_loss: 0.1433 - val_accuracy: 0.9608\n",
            "Epoch 495/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1732 - accuracy: 0.9500 - val_loss: 0.1431 - val_accuracy: 0.9610\n",
            "Epoch 496/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1730 - accuracy: 0.9501 - val_loss: 0.1430 - val_accuracy: 0.9612\n",
            "Epoch 497/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1727 - accuracy: 0.9501 - val_loss: 0.1428 - val_accuracy: 0.9613\n",
            "Epoch 498/500\n",
            "422/422 [==============================] - 2s 5ms/step - loss: 0.1725 - accuracy: 0.9502 - val_loss: 0.1426 - val_accuracy: 0.9612\n",
            "Epoch 499/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1723 - accuracy: 0.9503 - val_loss: 0.1424 - val_accuracy: 0.9612\n",
            "Epoch 500/500\n",
            "422/422 [==============================] - 2s 4ms/step - loss: 0.1721 - accuracy: 0.9503 - val_loss: 0.1423 - val_accuracy: 0.9612\n",
            "Test loss: 0.15888501703739166\n",
            "Test accuracy: 0.9544000029563904\n"
          ]
        }
      ],
      "source": [
        "# from __future__ import print_function\n",
        "# import keras\n",
        "# from keras.datasets import mnist\n",
        "# from keras.models import Sequential\n",
        "# from keras.layers import Dense, Dropout, Flatten\n",
        "# from keras.layers import Conv2D, MaxPooling2D\n",
        "# from keras import backend as K\n",
        "\n",
        "# batch_size = 128\n",
        "# num_classes = 10\n",
        "# epochs = 500\n",
        "\n",
        "# # input image dimensions\n",
        "# img_rows, img_cols = 28, 28\n",
        "\n",
        "# # the data, split between train and test sets\n",
        "# (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# if K.image_data_format() == 'channels_first':\n",
        "#     x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "#     x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "#     input_shape = (1, img_rows, img_cols)\n",
        "# else:\n",
        "#     x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "#     x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "#     input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "# x_train = x_train.astype('float32')\n",
        "# x_test = x_test.astype('float32')\n",
        "# x_train /= 255\n",
        "# x_test /= 255\n",
        "# print('x_train shape:', x_train.shape)\n",
        "# print(x_train.shape[0], 'train samples')\n",
        "# print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# # convert class vectors to binary class matrices\n",
        "# y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "# y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Conv2D(6, kernel_size=(5, 5),\n",
        "#                  strides=(1,1),\n",
        "#                  activation='tanh',\n",
        "#                  input_shape=input_shape))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
        "# model.add(Conv2D(6, (5, 5), strides=(1,1),activation='tanh'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
        "# # model.add(Dropout(0.25))\n",
        "# model.add(Flatten())\n",
        "# model.add(Dense(120, activation='tanh'))\n",
        "# # model.add(Dropout(0.25))\n",
        "# model.add(Dense(84, activation='tanh'))\n",
        "# # model.add(Dropout(0.25))\n",
        "# model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "# model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "#               optimizer=keras.optimizers.Adadelta(),\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.fit(x_train, y_train,\n",
        "#           batch_size=batch_size,\n",
        "#           epochs=epochs,\n",
        "#           verbose=1,\n",
        "#           validation_split=0.1)\n",
        "# score = model.evaluate(x_test, y_test, verbose=0)\n",
        "# print('Test loss:', score[0])\n",
        "# print('Test accuracy:', score[1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}